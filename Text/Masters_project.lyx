#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage[a4paper]{geometry}
\end_preamble
\use_default_options true
\begin_modules
theorems-std
theorems-sec
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Decision Theory
\end_layout

\begin_layout Author
Marko Sahan
\end_layout

\begin_layout Section
Introduction to Decision Theory
\end_layout

\begin_layout Standard
Decision process is complicated set of actions that living being makes for
 satisfying its needs.
 We want to apply same concept for inanimate thing such as computers.
 Before constructing some theory we must define some terms with which we
 will work.
 
\end_layout

\begin_layout Standard
Lets assume that we want to solve classification problem.
 For simplicity we will work with binary classification problem.
 We want to find such solution that will assign for each input value its
 class.
 Moreover, we want to make classification error as small as possible.
 Considering that input data 
\begin_inset Formula $\mathbf{x}\in{\bf X}\subset\mathbb{R}^{n}$
\end_inset

 and 
\begin_inset Formula $\mathbf{y\in}{\bf Y}$
\end_inset

, where 
\begin_inset Formula $\mathbf{x}$
\end_inset

 is an input vectors of size 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula ${\bf y}$
\end_inset

 is its labels assigned to the data from space 
\begin_inset Formula ${\bf X}$
\end_inset

.
 Each value from space 
\begin_inset Formula $\mathbf{Y}$
\end_inset

 is one or zero 
\begin_inset Formula $\mathbf{y}\in\{0,1\}$
\end_inset

 that represents first or second class.
\end_layout

\begin_layout Standard
In order to make a classification with respect to some input data we must
 provide an action or in other words decision.
 Let 
\begin_inset Formula $a\in\mathcal{A}$
\end_inset

 is an action and 
\begin_inset Formula $\mathcal{A}$
\end_inset

 is an action space.
 Of-course we do not want to make random decisions.
 We want to make decisions with respect to some metrics that can tell us
 how good our decision is.
 Thus, we will introduce a loss function 
\begin_inset Formula $L$
\end_inset

.
 From the previous text it is obvious that loss function will be dependent
 on action 
\begin_inset Formula $a\in\mathcal{A}$
\end_inset

.
 Furthermore, from the definition of the loss function it must be also dependent
 on a parameter.
 Let 
\begin_inset Formula $\theta\in\varTheta$
\end_inset

 is parameters' vector and 
\begin_inset Formula $\varTheta$
\end_inset

 is parameters space.
 As a result loss function 
\begin_inset Formula $L$
\end_inset

 can be represented as 
\begin_inset Formula 
\begin{equation}
L=L(\theta,a).\label{eq:loss_func}
\end{equation}

\end_inset

However its impossible to have all the data 
\begin_inset Formula $\theta\in\varTheta$
\end_inset

 and 
\begin_inset Formula $a\in\mathcal{A}$
\end_inset

.
 As a result we will introduce following definition.
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:expected_loss"

\end_inset

If 
\begin_inset Formula $\pi^{*}(\theta)$
\end_inset

 is believed probability distribution of 
\begin_inset Formula $\theta$
\end_inset

 at the time of decision making, the 
\shape slanted
Bayesian expected loss
\shape default
 of an action 
\begin_inset Formula $a$
\end_inset

 is 
\begin_inset Formula 
\begin{align}
\rho(\pi^{*},a)= & \mathbb{E}_{\pi^{*}}[L(\theta,a)],\label{eq:expected_loss-1}\\
= & \int_{\varTheta}L(\theta,a)dF^{\pi^{*}}(\theta)
\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Decision Theory and Support Vector Machine Algorithm
\begin_inset CommandInset label
LatexCommand label
name "subsec:decision_theory_svm"

\end_inset


\end_layout

\begin_layout Standard
In this subsection will continue construction of the decision theory on
 the example of Support Vector Machine (SVM) method.
 For simplicity lets consider linearly separable dataset.
 From the theoretical perspective SVM constructs hyperplane in high dimensional
 space that separates two classes.
 In this case our decision is a hyperplane that will separate two classes
 from each other.
 Equation of the hyperplane can be written as 
\begin_inset Formula $f(\mathbf{x},\mathbf{w},b)=\mathbf{w}^{T}\mathbf{x}+b$
\end_inset

 where 
\begin_inset Formula $\text{\ensuremath{\mathbf{w}}\ensuremath{\in\mathbb{R}^{n}} }$
\end_inset

 is a set of hyperplane parameters and 
\begin_inset Formula $b\in\mathbb{R}$
\end_inset

 is a bias .
 As a result, action space is represented as 
\begin_inset Formula $(\mathbb{R}^{n},\mathbb{R})\mathcal{=A}$
\end_inset

 and as a consequence tuple 
\begin_inset Formula $(\ensuremath{\mathbf{w}},b)\in\mathcal{A}$
\end_inset

.
 From this knowledge we can define 
\begin_inset Formula $\theta=(\mathbf{x},\mathbf{y})$
\end_inset

 where tuple 
\begin_inset Formula $(\mathbf{x},\mathbf{y})\in\mathbf{X}\times\mathbf{Y}$
\end_inset

 is parameters and 
\begin_inset Formula $\varTheta=\mathbf{X}\times\mathbf{Y}$
\end_inset

 is a parameters' space.
 Considering updated definitions, loss function (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:loss_func"
plural "false"
caps "false"
noprefix "false"

\end_inset

) can be rewritten as
\begin_inset Formula 
\begin{equation}
L=L(\mathbf{x},\mathbf{y},\mathbf{w},b).\label{eq:SVM_thoer_loss}
\end{equation}

\end_inset

Following task is to understand how good is our action (hyperplane estimation)
 with respect to the dataset.
 We can choose different types of the loss functions such as cross entropy
 or hinge loss, etc.
 The most basic approach for SVM method is hinge loss function which is
 defined as 
\begin_inset Formula 
\begin{equation}
L(\mathbf{x},\mathbf{y},\mathbf{w},b)=\max(0,1-{\bf y}\hat{\mathbf{y}}(\mathbf{x},\mathbf{w},b))\label{eq:hinge_loss}
\end{equation}

\end_inset

where 
\begin_inset Formula $\hat{\mathbf{y}}(\mathbf{x},\mathbf{w},b)=\mathbf{w}^{T}\mathbf{x}+b$
\end_inset

.
 
\end_layout

\begin_layout Standard
If we had available data 
\begin_inset Formula ${\bf X}$
\end_inset

 and it its labels 
\begin_inset Formula ${\bf Y}$
\end_inset

 we would not have to construct all this theory because all labels would
 be known and no classification problem must be solved.
 However, in most cases we would have little discrete subset 
\begin_inset Formula $\tilde{{\bf X}}\subset{\bf X}$
\end_inset

 and 
\begin_inset Formula $\tilde{{\bf Y}}\subset{\bf Y}$
\end_inset

.
 On the basis of 
\begin_inset Formula $\mathbf{\tilde{X}}$
\end_inset

 and 
\begin_inset Formula $\mathbf{\tilde{Y}}$
\end_inset

 we want to come up with a decision that will help us to label unlabeled
 data.
 In terms of SVM method we want to find such hyperplane that will label
 input values as a first class if it is 
\begin_inset Quotes eld
\end_inset

above
\begin_inset Quotes erd
\end_inset

 the hyperplane and as a second class if it is 
\begin_inset Quotes eld
\end_inset

below
\begin_inset Quotes erd
\end_inset

 the hyperplane.
 At this point very important assumption will be introduced.
 In order to find an optimal hyperplane we assume that the data 
\begin_inset Formula $\tilde{{\bf X}}$
\end_inset

 and its labels 
\begin_inset Formula $\tilde{{\bf Y}}$
\end_inset

 fully describe dataset 
\begin_inset Formula ${\bf X}$
\end_inset

 and 
\begin_inset Formula ${\bf Y}$
\end_inset

.
 Moreover we want to consider 
\begin_inset Formula $\mathbf{x}\in\mathbf{X}$
\end_inset

 and 
\begin_inset Formula $\mathbf{y\in}\mathbf{Y}$
\end_inset

 are random variables with joint probability density function 
\begin_inset Formula $p({\bf x},\mathbf{y})$
\end_inset

.
 We will also assume that 
\begin_inset Formula $\forall i\in\{1,..,N\},\ (\mathbf{x}_{i},\mathbf{y}_{i})\in\mathbf{\tilde{X}\times\tilde{Y}}$
\end_inset

 are independent identically distributed.
 Probability density function 
\begin_inset Formula $p(\mathbf{x},\mathbf{y})$
\end_inset

 can be written as 
\begin_inset Formula 
\begin{equation}
p(\mathbf{x},\mathbf{y})=p(\mathbf{y}|\mathbf{x})p(\mathbf{x}).\label{eq:joint_prob_dist}
\end{equation}

\end_inset

If we had those pdfs from (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:approx_of_joint_dist"
plural "false"
caps "false"
noprefix "false"

\end_inset

) we could easily derive its joint pdf.
 However, we have only 
\begin_inset Formula $\mathbf{\tilde{X}}$
\end_inset

 and 
\begin_inset Formula $\tilde{\mathbf{Y}}$
\end_inset

.
 As a result, with the usage of those data, probability density function
 
\begin_inset Formula $p({\bf x},\mathbf{y})$
\end_inset

 can be approximated as 
\begin_inset Formula 
\begin{equation}
p(\mathbf{x},\mathbf{y})=\frac{1}{N}\sum_{i=1}^{N}\delta(\mathbf{x}-\mathbf{x}_{i},\mathbf{y}-\mathbf{y}_{i})\label{eq:approx_of_joint_dist}
\end{equation}

\end_inset

where 
\begin_inset Formula $\delta(\mathbf{x}-\mathbf{x}_{i},\mathbf{y}-\mathbf{y}_{i})$
\end_inset

 is Dirac delta function which is centered in 
\begin_inset Formula $(\text{x}_{i},\mathbf{y}_{i})$
\end_inset

.
\end_layout

\begin_layout Standard
Using (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:expected_loss-1"
plural "false"
caps "false"
noprefix "false"

\end_inset

) we can evaluate expected loss function for SVM as follows 
\begin_inset Formula 
\begin{align*}
\mathbb{E}_{\pi^{*}}L & =\int_{\mathbf{X}\times\mathbf{Y}}L(\mathbf{x},\mathbf{y},\mathbf{w},b)p(\mathbf{x},\mathbf{y})d(\mathbf{x},\mathbf{y}),\\
 & =\int_{\mathbf{X}\times\mathbf{Y}}\max(0,1-{\bf y}\hat{\mathbf{y}}(\mathbf{x},\mathbf{w},b))\frac{1}{N}\sum_{i=1}^{N}\delta(\mathbf{x}-\mathbf{x}_{i},\mathbf{y}-\mathbf{y}_{i})d(\mathbf{x},\mathbf{y}),\\
 & =\frac{1}{N}\sum_{i=1}^{N}\max(0,1-{\bf y}_{i}\hat{\mathbf{y}}(\mathbf{x}_{i},\mathbf{w},b))
\end{align*}

\end_inset

where 
\begin_inset Formula $\hat{{\bf y}}(\mathbf{x}_{i},\mathbf{w},b)=\mathbf{w}^{T}\mathbf{x}_{i}+b.$
\end_inset

 Expect loss function for SVM can be written as 
\begin_inset Formula 
\begin{equation}
\rho(\mathbf{x}_{i},\mathbf{w},b)=\frac{1}{N}\sum_{i=1}^{N}\max(0,1-{\bf y}_{i}\mathbf{w}^{T}\mathbf{x}_{i}+b).\label{eq:expected_loss_SVM}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Decision Theory and Algorithm Based on Neural Network Function 
\begin_inset CommandInset label
LatexCommand label
name "subsec:decision_theory_nn"

\end_inset


\end_layout

\begin_layout Standard
Decision Theory construction for the algorithm, based on a neural network
 function, is mostly the same as in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:decision_theory_svm"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 However in this case our decision is to finds estimate 
\begin_inset Formula $\mathbf{\hat{y}}=\mathbf{\hat{y}}(\mathbf{x},\mathbf{W},\mathbf{b})$
\end_inset

 of the probability density function 
\begin_inset Formula $p(\mathbf{y}|\mathbf{x})$
\end_inset

 where 
\begin_inset Formula $\mathbf{x}$
\end_inset

 is the input data, 
\series bold

\begin_inset Formula $\mathbf{y}$
\end_inset


\series default
 is the label assigned to 
\begin_inset Formula $\mathbf{x}$
\end_inset

, 
\begin_inset Formula $\mathbf{W}$
\end_inset

 is a set of neural network function parameters and 
\begin_inset Formula $\mathbf{b}$
\end_inset

 is a vector of biases.
 Once again our action space 
\begin_inset Formula $\mathcal{A}$
\end_inset

 will be parameters' and biases' space of 
\begin_inset Formula $\mathbf{\hat{y}}$
\end_inset

.
 Same as in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:decision_theory_svm"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we can define 
\begin_inset Formula $(\mathbf{x},\mathbf{y})$
\end_inset

 are parameters of the loss function and 
\begin_inset Formula $\mathbf{X}\times\mathbf{Y}$
\end_inset

 is a parameters' space.
 For better understanding of the variety of loss functions we will use cross
 entropy loss function that is defined as 
\begin_inset Formula 
\begin{equation}
L(\mathbf{x},\mathbf{y},\mathbf{w},b)=\mathbf{y}\ln\big(\hat{\mathbf{y}}(\mathbf{x},\mathbf{w},b)\big)+(1-\mathbf{y})\ln\big((1-\hat{\mathbf{y}}(\mathbf{x},\mathbf{w},b)\big).\label{eq:cross_entropy_loss}
\end{equation}

\end_inset

Continuing using assumptions from 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:decision_theory_svm"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we consider 
\begin_inset Formula $\mathbf{x}\in\mathbf{X}$
\end_inset

 and 
\begin_inset Formula $\mathbf{y\in}\mathbf{Y}$
\end_inset

 are random variables with joint probability density function 
\begin_inset Formula $p({\bf x},\mathbf{y})$
\end_inset

.
 With the usage of the given dataset where 
\begin_inset Formula $\forall i\in\{1,..,N\},\ (\mathbf{x}_{i},\mathbf{y}_{i})\in\mathbf{\tilde{X}\times\tilde{Y}}$
\end_inset

 are independent identically distributed we can approximate 
\begin_inset Formula $p(\mathbf{x},\mathbf{y})$
\end_inset

 as 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:approx_of_joint_dist"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Applying definition 
\begin_inset CommandInset ref
LatexCommand ref
reference "def:expected_loss"
plural "false"
caps "false"
noprefix "false"

\end_inset

, expected loss for the algorithm based on a neural network function is
 evaluated as 
\begin_inset Formula 
\begin{align}
\mathbb{E}_{\pi^{*}}L & =\int_{\mathbf{X}\times\mathbf{Y}}L(\mathbf{x},\mathbf{y},\mathbf{w},b)p(\mathbf{x},\mathbf{y})d(\mathbf{x},\mathbf{y}),\nonumber \\
 & \int_{\mathbf{X}\times\mathbf{Y}}\Big(\mathbf{y}\ln\big(\hat{\mathbf{y}}(\mathbf{x},\mathbf{w},b)\big)+(1-\mathbf{y})\ln\big((1-\hat{\mathbf{y}}(\mathbf{x},\mathbf{w},b)\big)\Big)\frac{1}{N}\sum_{i=1}^{N}\delta(\mathbf{x}-\mathbf{x}_{i},\mathbf{y}-\mathbf{y}_{i})d(\mathbf{x},\mathbf{y}),\nonumber \\
 & \frac{1}{N}\sum_{i=1}^{N}\Big(\mathbf{y}_{i}\ln\big(\hat{\mathbf{y}}_{i}(\mathbf{x},\mathbf{w},b)\big)+(1-\mathbf{y}_{i})\ln\big((1-\hat{\mathbf{y}}_{i}(\mathbf{x},\mathbf{w},b)\big)\Big).\label{eq:expected_loss_cross_entropy}
\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Decision Theory and Naive Bayes Algorithm
\begin_inset CommandInset label
LatexCommand label
name "subsec:decision_theory_nb"

\end_inset


\end_layout

\begin_layout Standard
Naive Bayes algorithm same as neural network based algorithms or SVM tries
 to estimate 
\begin_inset Formula $\hat{\mathbf{y}}=\mathbf{\hat{y}}(\mathbf{y},\mathbf{x},\mathbf{w})$
\end_inset

 of probability density function 
\begin_inset Formula $p(\mathbf{y}|\mathbf{x})$
\end_inset

 where 
\begin_inset Formula $\mathbf{w}$
\end_inset

 is set of parameters of function 
\begin_inset Formula $\hat{\mathbf{y}}$
\end_inset

, 
\begin_inset Formula $\mathbf{x}$
\end_inset

 is the input data and 
\series bold

\begin_inset Formula $\mathbf{y}$
\end_inset

 
\series default
is the label assigned to 
\begin_inset Formula $\mathbf{x}$
\end_inset

.
 Before continuing with a loss function construction we would like to go
 trough Naive Bayes (NB) method.
 With the usage of Bayes rule we can rewrite
\series bold
 
\series default

\begin_inset Formula $p(\mathbf{y}|\mathbf{x})$
\end_inset

 as follows 
\begin_inset Formula 
\begin{equation}
p(\mathbf{y}|\mathbf{x})=\frac{p(\mathbf{x}|\mathbf{y})p(\mathbf{y})}{\int_{\mathbf{Y}}p(\mathbf{x}|\mathbf{y})p(\mathbf{y})d\mathbf{y}}.\label{eq:bayes_rule}
\end{equation}

\end_inset

However, Naive Bayes method introduces in equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:bayes_rule"
plural "false"
caps "false"
noprefix "false"

\end_inset

) very strong assumption that features of vector 
\begin_inset Formula $\mathbf{x}=(x_{1},x_{2},...,x_{n})^{T}$
\end_inset

 are conditionally independent.
 As a result estimation of 
\begin_inset Formula $\mathbf{\hat{y}}$
\end_inset

 is 
\begin_inset Formula 
\begin{equation}
\hat{\mathbf{y}}(\mathbf{y},\mathbf{x},\mathbf{w})=\frac{1}{Z}p(\mathbf{y})\prod_{i=1}^{n}p(x_{i}|\mathbf{y}),\label{eq:naive_bayes_eq}
\end{equation}

\end_inset

where 
\series bold

\begin_inset Formula $p(\mathbf{y})$
\end_inset


\series default
 is probability density function of the labels and
\series bold
 
\series default

\begin_inset Formula $p(x_{i}|\mathbf{y})$
\end_inset

 is a probability density function of the data features conditioned with
 label.
 Vector of parameters 
\begin_inset Formula $\mathbf{w}$
\end_inset

 in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:naive_bayes_eq"
plural "false"
caps "false"
noprefix "false"

\end_inset

) represents parameters of the 
\begin_inset Formula $p(x_{i}|\mathbf{y})$
\end_inset

.
 In this case we could also use same loss functions as for 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:decision_theory_svm"
plural "false"
caps "false"
noprefix "false"

\end_inset

 or 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:decision_theory_nn"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 However we will use here zero-one loss function that is defined as 
\begin_inset Formula 
\begin{equation}
L(\mathbf{y},\mathbf{x},\mathbf{w})=\begin{cases}
1 & \mathbf{y\neq\hat{y}(\mathbf{y},\mathbf{x},\mathbf{w})}\\
0 & \mathbf{y}=\hat{y}(\mathbf{y},\mathbf{x},\mathbf{w})
\end{cases}.\label{eq:zero-one_loss}
\end{equation}

\end_inset

Due to the fact that we use zero-one loss function we must set the assumption
 that 
\begin_inset Formula $\mathbf{\hat{y}}\in\{0,1\}$
\end_inset

.
 Same as in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:decision_theory_svm"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:decision_theory_nn"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we will assume that we can approximate 
\begin_inset Formula $p(\mathbf{x},\mathbf{y})$
\end_inset

 as 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:approx_of_joint_dist"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 From this moment everything is ready for deriving expected loss function.
 Expected loss function for Naive Bayes method is derived as 
\series bold

\begin_inset Formula 
\begin{align}
\mathbb{E}_{\pi^{*}}L & =\int_{\mathbf{X}\times\mathbf{Y}}L(\mathbf{x},\mathbf{y},\mathbf{w})p(\mathbf{x},\mathbf{y})d(\mathbf{x},\mathbf{y}),\nonumber \\
 & \int_{\mathbf{X}\times\mathbf{Y}}L(\mathbf{x},\mathbf{y},\mathbf{w})\frac{1}{N}\sum_{i=1}^{N}\delta(\mathbf{x}-\mathbf{x}_{i},\mathbf{y}-\mathbf{y}_{i})d(\mathbf{x},\mathbf{y}),\nonumber \\
 & \frac{1}{N}\sum_{i=1}^{N}L(\mathbf{x}_{i},\mathbf{y}_{i},\mathbf{w}).\label{eq:expected_loss_zero_one}
\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Decision Theory and Random Forest Algorithm
\end_layout

\begin_layout Standard
In order to work with random forests we must precisely define decision trees
 and only then construct theory for random forests.
\end_layout

\begin_layout Subsubsection
Decision Tree
\end_layout

\begin_layout Standard
In this section we expect our decision three to give us also an estimate
 
\begin_inset Formula $\hat{\mathbf{y}}(\mathbf{y},\mathbf{x},\mathbf{w})$
\end_inset

 of 
\begin_inset Formula $p(\mathbf{y}|\mathbf{x})$
\end_inset

 where 
\begin_inset Formula $\mathbf{w}$
\end_inset

 is a vector of Yes or No decisions, 
\begin_inset Formula $\mathbf{x}\in{\bf X}\subset\mathbb{R}^{n}$
\end_inset

 and 
\begin_inset Formula $\mathbf{y\in}{\bf Y}$
\end_inset

, where 
\begin_inset Formula $\mathbf{x}$
\end_inset

 is an input vectors of size 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula ${\bf y}$
\end_inset

 is its labels assigned to the data from space 
\begin_inset Formula ${\bf X}$
\end_inset

.
 Parameter space will be same as in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:decision_theory_svm"
plural "false"
caps "false"
noprefix "false"

\end_inset

-
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:decision_theory_nb"
plural "false"
caps "false"
noprefix "false"

\end_inset

, whereas action 
\begin_inset Formula $a\in{\cal A}$
\end_inset

 will represent a vector of Yes and No decisions 
\begin_inset Formula $\mathbf{w}$
\end_inset

.
 Each feature bla bla bla...
\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
